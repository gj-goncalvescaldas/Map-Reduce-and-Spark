{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrUd6vAZCY/M5qjZfSkw5+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gj-goncalvescaldas/Map-Reduce-and-Spark/blob/main/Spark_Setup_and_Basic_Data_Processing_in_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description:**\n",
        "\n",
        "This Jupyter notebook provides a step-by-step guide to setting up Apache Spark in a Google Colab environment and demonstrates basic data processing tasks using PySpark. The notebook covers the installation of necessary dependencies, initialization of Spark, creation of DataFrames, text file processing, and CSV file handling. Each block of code includes concise explanations to help understand the purpose and functionality of the operations performed.\n"
      ],
      "metadata": {
        "id": "0g3bEIQygwYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# install spark (change the version number if needed)\n",
        "#!wget -q https://archive.apache.org/dist/spark/spark-3.5.1/spark-3.5.1-bin-hadoop3.tgz\n",
        "\n",
        "# unzip the spark file to the current folder\n",
        "!tar xf spark-3.5.1-bin-hadoop3.tgz\n",
        "\n",
        "# set your spark folder to your system path environment\n",
        "import os\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.1-bin-hadoop3\"\n",
        "\n",
        "# install findspark using pip\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "VxlEnPTiCSnd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "*  Install Java: Installs OpenJDK 8 without displaying output to the terminal.\n",
        "*  Download Spark: Downloads Spark version 3.5.1 (commented out, can be uncommented if needed).\n",
        "* Unzip Spark: Extracts the downloaded Spark file.\n",
        "* Set Environment Variables: Sets the environment variables for Java and Spark to ensure they are properly configured.\n",
        "* Install findspark: Installs the findspark package to help locate the Spark installation."
      ],
      "metadata": {
        "id": "QZko2THVfdVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "df = spark.createDataFrame([{\"hello\": \"world\"} for x in range(1000)])\n",
        "df.show(3, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHah1yv4Cyd_",
        "outputId": "71edf789-fa05-4a8e-f441-4a6313a25e67"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|world|\n",
            "|world|\n",
            "|world|\n",
            "+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "*  Initialize findspark: Prepares the environment for using PySpark.\n",
        "*  Create SparkSession: Starts a Spark session that uses all available local cores.\n",
        "* Create DataFrame: Creates a DataFrame with 1000 rows, each containing the key-value pair {\"hello\": \"world\"}.\n",
        "* Show DataFrame: Displays the first 3 rows of the DataFrame without truncating the values.\n",
        "\n"
      ],
      "metadata": {
        "id": "QWdX9YnHfwj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "file = sc.textFile(\"/DATA/el_quijote.txt\")\n",
        "words = file.flatMap(lambda line: line.split(\" \"))\n",
        "wordCounts = words.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
        "for x in wordCounts.take(10):\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNeqM7RnLw7V",
        "outputId": "44953d15-af94-4367-a914-84913c42c072"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('DE', 17)\n",
            "('LA', 13)\n",
            "('Miguel', 3)\n",
            "('', 1)\n",
            "('PRIMERA', 1)\n",
            "('CAPÍTULO', 1)\n",
            "('1:', 1)\n",
            "('condición', 23)\n",
            "('y', 8042)\n",
            "('del', 1113)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "*  Get SparkContext: Retrieves the current SparkContext from the Spark session.\n",
        "*  Read Text File: Reads the text file \"el_quijote.txt\" as an RDD.\n",
        "* Split into Words: Splits each line of the text into individual words.\n",
        "* Count Words: Maps each word to a (word, 1) pair and reduces by key to count the occurrences of each word.\n",
        "* Show Word Counts: Prints the first 10 word counts.\n",
        "\n"
      ],
      "metadata": {
        "id": "n4QUZcgdf5JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ficheroVentas = spark.read.csv(\"/DATA/ventas_zapatos.csv\", header=True, sep=\";\")\n",
        "ficheroVentas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsa_wFqLOgPM",
        "outputId": "f62bbb1c-40cc-4742-d767-a904d86f0b1d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+---------------+----------+----------+----------+-------+--------------------+-------------+----------------+------+\n",
            "|           Fecha|     id_cliente|    nombre|apellido_1|apellido_2|id_prod|         nombre_prod|material_prod|  categoria_prod|precio|\n",
            "+----------------+---------------+----------+----------+----------+-------+--------------------+-------------+----------------+------+\n",
            "| 20/04/2019 4:19|995052178892353|   Fabiola|    Méndez|     Ramos| 562972|   Pelusa mercenario|       Gamuza|      Zapatillas|    75|\n",
            "| 10/02/2019 3:32|528848914440944|   Basileo|    Alonso|   Esteban| 949966| Reforma capitalista|         Goma|Zapatos de tacón|    50|\n",
            "|08/05/2019 19:11| 53146869174343|    Míriam|  Martínez|   Esteban| 432964|    Zoca coxofemoral|       Gamuza|Zapato de vestir|    70|\n",
            "|22/04/2019 15:24| 95327509355920|    Teresa|   Garrido|    Castro| 842352|Número Primo cham...|         Goma|         Botines|    50|\n",
            "|02/01/2019 10:01|560935930327708|   Natalia|    Vargas| Rodríguez| 816218|     Mejora burkinés|        Cuero|      Zapatillas|    85|\n",
            "|15/01/2019 15:20|518843488250634|      José|    Ibáñez|  González| 612297|    Retín dehiscente|        Cuero|         Botines|    90|\n",
            "|03/05/2019 23:46|268300738882486|  Verónica|      Ruiz|   Garrido| 227744|      Ñinga sediento|       Gamuza|Zapato de vestir|    65|\n",
            "|26/01/2019 13:00|209058654202699|   Miqueas|   Montoro|    Martín| 890119|Predecesor cincuenta|       Gamuza|Zapatos de tacón|    75|\n",
            "| 28/04/2019 5:44|956967795276369|  Casimiro|   Vázquez|    Flores| 968238|Fungistático peri...|         Tela|      Zapatillas|    40|\n",
            "| 23/04/2019 3:28|688099529240320| Natividad|     Parra|    Campos| 287558|Rebullicio absolv...|       Gamuza|         Botines|    70|\n",
            "| 03/04/2019 1:35| 65850855751971|   Teodora|       Gil|   Aguilar| 949966| Reforma capitalista|         Goma|Zapatos de tacón|    50|\n",
            "|17/04/2019 14:25|552395408874921|   Cecilia|   Serrano|    Pastor| 284282|      Viruta asesado|         Tela|      Zapatillas|    40|\n",
            "| 10/04/2019 0:54| 28534471721604|     Nuria| Domínguez|    Lozano| 144844|Excrecencia arbol...|       Gamuza|         Botines|    60|\n",
            "|29/04/2019 21:50|296454476859060|  Josefina|    Santos|     Muñoz| 770874|   Náufrago tarateño|        Cuero| Zapatos de agua|    90|\n",
            "| 25/04/2019 1:08|637401250128217|   Eusebio|   Sánchez|     Núñez| 463228|  Pésame contractual|       Gamuza|      Zapatillas|    70|\n",
            "|01/02/2019 23:26|745520267958410|   Edmundo|    Pastor|     Soler| 724303|  Cobardón camboyano|   Sintéticos|      Zapatillas|    35|\n",
            "| 09/02/2019 6:12|248544781588493|     Celso|   Serrano|   Jiménez| 910881|Sucesión Converge...|       Gamuza|Zapatos de tacón|    65|\n",
            "| 25/01/2019 3:05|412564651502106|Segismundo|      Sanz|  González| 816218|     Mejora burkinés|        Cuero|      Zapatillas|    85|\n",
            "|11/05/2019 19:46|874761004374001|    Lázaro|   Montero|     Arias| 294040| Brazalete resbaloso|         Goma|Zapato de vestir|    40|\n",
            "|04/05/2019 12:25|574629118992248|    Ángela|   Vázquez|     Gómez| 693737|Beritense intratable|         Goma|         Botines|    55|\n",
            "+----------------+---------------+----------+----------+----------+-------+--------------------+-------------+----------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "*  Read CSV File: Reads the CSV file \"ventas_zapatos.csv\" into a DataFrame with headers and fields separated by a semicolon.\n",
        "*  Show DataFrame: Displays the contents of the DataFrame."
      ],
      "metadata": {
        "id": "0620ERBogLDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importePorMaterial = ficheroVentas.rdd.map(lambda row: (row[\"material_prod\"], int(row[\"precio\"]))).reduceByKey(lambda a, b: a + b)\n",
        "importePorMaterial.toDF().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoaCmhQgc2xP",
        "outputId": "531d064f-868e-4f1d-cff6-2e3d5f0cff54"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+\n",
            "|        _1|      _2|\n",
            "+----------+--------+\n",
            "|    Gamuza|21056140|\n",
            "|     Cuero|13324110|\n",
            "|      Tela| 9974005|\n",
            "|      Goma| 9629235|\n",
            "|Sintéticos| 2175200|\n",
            "+----------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "\n",
        "*  Map and Reduce: Maps each row to a (material, price) pair and reduces by key to sum the prices for each material.\n",
        "*  Convert and Show: Converts the result back to a DataFrame and displays it."
      ],
      "metadata": {
        "id": "JONpq2C_gS52"
      }
    }
  ]
}