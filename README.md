# Spark-and-Pyspark

# Apache Spark Use

This repository contains Jupyter notebooks that demonstrate the use of Apache Spark. The notebooks are designed to guide you through the process of setting up Spark, processing data, and performing various data analysis tasks using PySpark.

## Notebooks

### 1. Spark Setup and Basic Data Processing in PySpark

**File Name:** `1_Spark_Setup_and_Basic_Data_Processing_in_PySpark.ipynb`

**Description:** This Jupyter notebook provides a step-by-step guide to setting up Apache Spark in a Google Colab environment and demonstrates basic data processing tasks using PySpark. The notebook covers the installation of necessary dependencies, initialization of Spark, creation of DataFrames, text file processing, and CSV file handling. Each block of code includes concise explanations to help understand the purpose and functionality of the operations performed.

### 2. Spark Shoe Sales Analysis

**File Name:** `2_spark_shoe_sales_analysis.ipynb`

**Description:** This Jupyter notebook demonstrates the analysis of shoe sales data using PySpark. It includes reading CSV data, transforming and enriching the dataset, creating DataMarts for various dimensions, and performing aggregations to analyze sales by client, product, and time period. The notebook provides detailed code and explanations for each step, ensuring clarity and understanding.

## Repository Structure

```plaintext
├── 1_Spark_Setup_and_Basic_Data_Processing_in_PySpark.ipynb
├── 2_spark_shoe_sales_analysis.ipynb
├── data
│   ├── ventas_zapatos.csv
│   ├── datamart_clientes.csv
└── README.md
